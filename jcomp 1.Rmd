---
title: "Data Analytics Project"
output: html_notebook
---

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
```

```{r}
#reading dataset
hrm<-read.csv('HR_comma_sep.csv')
head(hrm)
```

```{r}
#checking for null values in the dataset
any(is.na(df))
```
```{r}
#Structure of the Dataset
str(hrm)
attach(hrm)
```
```{r}
#converting left variable to factor variable 
hrm$left<-factor(hrm$left,labels=c("True","False"))
table(hrm$left)

#Summary Statistics of the dataset
summary(hrm)
```
```{r}
#Time spend at company vs Left or not

table(hrm$time_spend_company)

ggplot(aes(x = factor(time_spend_company)),data = hrm) + 
  geom_bar(fill = 'purple',color='black') + 
  xlab("Time spend at compnay in years") + 
  ylab("Frequency")+
  labs(title = "Barplot of Time spend at Company")

ggplot(aes(x = factor(time_spend_company)),data = hrm) + 
  geom_bar(fill = 'grey',color='black') + 
  xlab("Time spend at compnay in years") + 
  ylab("Frequency")+
  labs(title = "Barplot of Time spend at Company faceted by Left")  +
  facet_wrap(~left)

by(hrm$time_spend_company , hrm$left , summary)

ggplot(aes(x = left , y
           = time_spend_company),data = hrm)+
  geom_boxplot()
```
```{r}
#Time spend vs Satisfaction level of employees as they worked

by(hrm$satisfaction_level,factor(hrm$time_spend_company),summary)

cor.test(hrm$satisfaction_level,hrm$time_spend_company)

#Time spend increases, the satisfaction level has decreased
```
```{r}
#Analysis of Department of Work
ggplot(aes(x =sales),data = hrm ) +
  geom_bar()  +
  xlab('Department') + 
  ylab('Counts') +
  coord_flip() 
#highest count is for Sales department then Technical  and least for 
#Management
```
```{r}
#Department vs salary

table(Dept = hrm$sales , Salary  = hrm$salary)

ggplot(aes(x =sales),data = hrm ) +
  geom_bar(aes(fill=salary))  +
  xlab('Department') + 
  ylab('Counts') +
  coord_flip()


ggplot(aes(x =sales),data = hrm ) +
  geom_bar(aes(fill=salary))  +
  xlab('Department') + 
  ylab('Counts') +
  labs(title = "Department and their count facetted by Salary ranges")+
  facet_wrap(~salary) + 
  coord_flip()

chisq.test(hrm$sales,hrm$salary)
#Department and Salary is dependent on each other
```

```{r}
#Plot of Department vs Percentage of Employees who left
deptdf<-hrm %>% group_by(sales,left) %>% 
      summarise(count=n())

#making a data frame of Departments and the count of workers who left or not
deptdf<-spread(deptdf,left,count)

deptdf<-transform(deptdf,Perleft=(True/(True+False))*100 , PerWork=(False/(True+False))*100)
deptdf


ggplot(aes(x=sales, y = Perleft),data = deptdf) + 
  geom_col(fill='#53ab85',color='#2f3f52') + 
  coord_flip()+
  xlab("Department") + 
  ylab("Percentage of Employees who left") + 
  labs(title="Plot of Department vs Percentage of Employee left")
#highest percentage of employees belonged to HR dept then accounting
#least for management dept who left

```

```{r}
#Department vs Satisfaction level

by(hrm$satisfaction_level,hrm$sales,summary)
#highest mean satisfaction for R&D and Management Dept

ggplot(aes(x = sales, y = satisfaction_level),data = hrm)+
  geom_boxplot() + 
  scale_y_sqrt()+
  xlab('Department') + 
  ylab('Satisfaction Level"') + 
  coord_flip()
#Highest Median Satisfaction for IT dept, R&D and , Management
#Least Median Satifaction level for HR and Accounting

```
```{r}
#Department vs Satisfaction level

by(hrm$satisfaction_level,hrm$sales,summary)
#highest mean satisfaction for R&D and Management Dept

ggplot(aes(x = sales, y = satisfaction_level),data = hrm)+
  geom_boxplot() + 
  scale_y_sqrt()+
  xlab('Department') + 
  ylab('Satisfaction Level"') + 
  coord_flip()
#Highest Median Satisfaction for IT dept, R&D and , Management
#Least Median Satifaction level for HR and Accounting
```
```{r}
#DATA PREPROCESSING
library(ggcorrplot)
str(hrm[-7])
corr_matrix <- cor(hrm[,-c(7,9)])
ggcorrplot(corr_matrix, type = "full", lab = TRUE, lab_size = 3, colors = c("#6D9EC1", "white", "#E46726"), title = "Correlation Matrix", outline.color = "white", legend.title = "Correlation")
# Convert the correlation matrix to a data frame
corr_df <- as.data.frame(as.table(corr_matrix))

# Order the correlation matrix by ascending order of correlation coefficients
ordered_corr_df <- corr_df[order(abs(corr_df$Freq)),]

# Get the features with the lowest correlation coefficients
lowest_corr_features <- unique(c(ordered_corr_df$Var1[1:5], ordered_corr_df$Var2[1:5]))

# Print the features with the lowest correlation coefficients
print(lowest_corr_features)

#Generating Training and Test Data
summary(hrm)
set.seed(122)
library(dplyr)

#converting catogarical to numeric
salary_num <- unclass(as.factor(hrm$salary))
sales_num <- unclass(as.factor(hrm$sales))

#"accounting", "hr","IT",management","marketing","product_mng","RandD","sales",support","technical" 
hrm[,c("sales")] <- sales_num
attr(sales_num,"levels")
#high low medium
hrm[c("salary")] <- salary_num
attr(salary_num,"levels")

head(hrm)

#making a function which takes a vector x and uses max-min normalization to normalize it
#to a range-0 to 1
normal<-function(x)
{
  norm_x<-(x-min(x))/(max(x)-min(x))
  norm_x
}
hrm[,3:5]<-normal(hrm[,3:5])

# Shuffling the dataset
n <- nrow(hrm)
hrms <- hrm[sample(n),]

#Splitting of dataset
train_indices <- 1:round(0.7 * n)
train <-hrms[train_indices,]
train_X <- hrms[train_indices,c(1,2,3,4,5,6,8,9)]
train_Y <- hrms[train_indices,c(1,2,3,4,5,6,8,9)]
test_indices <- (round(0.7 * n) + 1):n
test <- hrms[train_indices,]
test_X <- hrms[train_indices,c(1,2,3,4,5,6,8,9)]
test_Y <- hrms[test_indices,7]



```


```{r}
#2) K - NEAREST NEIGHBOUR
#Using K-NN to predict the Satisfaction Level

#Requiring the package which has K-NN regression
require(FNN)
library(caret)
testdf<-hrm[10000:14000,]
train<-hrm[1:9999,]

#SELECTING THE BEST HYPERPARAMETERS
knn_model <- train(as.factor(left) ~ ., data = train, method = "knn", 
                   trControl = trainControl(method = "cv", number = 10),
                   tuneLength = 10, metric="Accuracy") 
print(knn_model$bestTune)
print(knn_model$results)

#MODEL
modKnn<-knn.reg(select(train,average_montly_hours,time_spend_company,number_project,left),select(testdf,average_montly_hours,time_spend_company,number_project,left),train[,1],k=7,algorithm=c("kd_tree"))

knn_model <- train(left ~ ., data = train, method = "knn", 
                   trControl = trainControl(method = "cv", number = 10),
                   tuneGrid = expand.grid(k = 5))

# Make predictions on the test set
predictions <- predict(knn_model, newdata = testdf)
predictions <- as.integer(predictions)
# Calculate accuracy
accuracy <- confusionMatrix(factor(predictions),factor(testdf$left))$overall["Accuracy"]
print(paste("Accuracy of KNN model:", accuracy))
cat("Standard error: ", knn_model$results$Accuracy[1], "\n")
cat("Mean squared error: ", mean(knn_model$resample$RMSE), "\n")
cat("Residual standard error: ", sd(knn_model$resample$Resample), "\n")

preddf<-data.frame(Actual =testdf$satisfaction_level,
                   Predicted = modKnn$pred)

preddf<-preddf %>% mutate(Residuals=abs(Actual-Predicted))

ggplot(aes(x = Residuals ),data  = preddf)  + 
  geom_histogram(color='black',fill='green',bins=40,binwidth = 0.01) + 
  scale_x_continuous(breaks=seq(0,0.7,0.05)) + 
  labs(x = "Residual Values i.e (Actual Target - Predicted Target)",y = "Counts",
       title = "Plot of Residuals Values for K-NN with 5 as K") + 
  coord_cartesian(ylim=c(0,400)) + 
  scale_y_continuous(breaks = seq(0,400,50))


#Hence K-NN gave better results on the Test Set

```
```{r}
#DECISION TREE

#setting seed for reproducable results
set.seed(122)

#normalizing the variables
#making a function which takes a vector x and uses max-min normalization to normalize it
#to a range-0 to 1
normal<-function(x)
{
  norm_x<-(x-min(x))/(max(x)-min(x))
  norm_x
}
library(datasets)
library(caTools)
library(party)
library(dplyr)
library(magrittr)
library(DT)
library(rpart)
library(rattle)
library(rpart.plot)
library(RColorBrewer)
library(caret)
## SELECTING THE BEST HYPERPARAMETERS
train_control <- trainControl(method = "cv", number = 5)
hyperparams <- expand.grid(
   
cp = seq(0.001, 0.1, length.out = 10)
 
)
model <- train(
  as.factor(left) ~ .,
  data = train,
  method = "rpart",
  tuneGrid = hyperparams,
  trControl = train_control,
  metric = "Accuracy"
)
print(model$bestTune)
print(model$results)

#MODEL
tree <- rpart(left~., train, method = "class", cp=0.001, minsplit=2, minbucket=1)
fancyRpartPlot(tree)
pred_test <- predict(tree, testdf, type = "class")
# Calculate the accuracy of the model
accuracy <- sum(pred_test == testdf$left) / nrow(testdf)

# Print the accuracy
print(paste("The accuracy of the model is: ",accuracy*100,"%"))

```
```{r}
#RANDOM FOREST

#SELECTING THE BEST PARAMETERS
# define the training control
train_control <- trainControl(method = "cv", number = 10)

# define the tuning grid
tuning_grid <- expand.grid(mtry = c(1,2, 3, 4,5))

# train the model
model <- train(as.factor(left) ~ ., data = train, method = "rf", trControl = train_control, tuneGrid = tuning_grid)

# print the best tuning parameters and accuracy
print(paste("Best Parameters: ", model$bestTune, "\n"))
print(model$results)
# assume rf_fit is the tuned random forest model object
# assume test_data is the test dataset
print(rf_tune)
# predict using the tuned model
#rf_pred <- predict(model, newdata = testdf)

# calculate RMSE
#rf_rmse <- sqrt(mean((rf_pred - testdf$left)^2))

# print RMSE
#print(paste("RMSE for tuned random forest model:", rf_rmse))

```

```{r}
library(randomForest)
library(caTools)
library(caret)

df<-data.frame(read.csv('HR_comma_sep.csv'))
scaled = preProcess(df, method=c("range"))
df = predict(scaled, df)
      
split = sample.split(df, SplitRatio = 0.7)
train = subset(df, split == "TRUE")
test = subset(df, split == "FALSE")

train$left <- as.character(train$left)
train$left <- as.factor(train$left)

set.seed(42)

model = randomForest(x = train[-7], y = train$left, ntree=100,mtry=3)
model

y_pred = predict(model, newdata = test[-7])

# Confusion Matrix
confusion_mtx = table(test[, 7], y_pred)
confusion_mtx

# Plotting model
plot(model)

# Importance plot
varImpPlot(model)

# Accuracy
accuracy_Test = sum(diag(confusion_mtx)) / sum(confusion_mtx)
paste('Accuracy for test', accuracy_Test*100, '%')

# intially the accuracy was 98% for ntree= 500,
# then the ntree changed to 100, accuracy became 99%. 
# Reducing the number of trees in a random forest model can sometimes improve accuracy because it can help to reduce overfitting.
```



```{r}
### ENSEMBLE MODEL

library(randomForest)
library(caTools)
library(party)

# Load the dataset
df<-data.frame(read.csv('HR_comma_sep.csv'))

# Split the dataset into training and testing sets
split = sample.split(df, SplitRatio = 0.7)
train = subset(df, split == "TRUE")
test = subset(df, split == "FALSE")

# Convert the left variable to a factor
train$left <- as.factor(train$left)

# Train the Decision Tree model
tree_model <- rpart(left~., train, method = "class",cp=0.001, minsplit=2, minbucket=1)

# Train the Random Forest model
set.seed(42)
rf_model <- randomForest(x = train[-7], y = train$left, ntree=100,mtry=10)

# Make predictions using both models
tree_pred <- predict(tree_model, test, type = "class")
rf_pred <- predict(rf_model, newdata = test[-7])

# Combine the predictions using majority voting
ensemble_pred <- ifelse((as.numeric(tree_pred) + as.numeric(rf_pred)) > 1, 1, 0)


# Compute accuracy of the ensemble model
ensemble_conf <- table(test$left, ensemble_pred)
ensemble_acc <- sum(diag(ensemble_conf))/sum(ensemble_conf)
paste("The accuracy of the ensemble model is:", ensemble_acc*100, "%")


```

```{r}
#PARAMETER SETTING
tuneGrid <- expand.grid(sigma = c(0.1, 0.2, 0.3,0.4,0.5),
                        C = c(1, 10, 100,500, 1000))

svmFit <- train(left ~ ., data = train, method = "svmRadial", 
                tuneGrid = tuneGrid, trControl = trainControl(method = "cv", number = 5),metric="Accuracy")

svmFit$bestTune
svmFit$results

```


```{r}

### SUPPORT VECTOR MACHINE MODEL

# Load required libraries
library(e1071)

# Load the HR dataset
df <- read.csv('HR_comma_sep.csv')

# Split data into training and testing sets
set.seed(122)
split <- sample.split(df$left, SplitRatio = 0.7)
train <- df[split, ]
test <- df[!split, ]

# Convert target variable to factor
train$left <- as.factor(train$left)

# Train a SVM model
svm_model_linear <- svm(left ~ ., data = train, kernel = "linear")
svm_model_poly <- svm(left ~ ., data = train, kernel = "polynomial")
svm_model_radial <- svm(left ~ ., data = train, kernel = "radial",sigma=0.3,cost=10)
svm_model_sigmoid <- svm(left ~ ., data = train, kernel = "sigmoid")

# Make predictions on test set
svm_pred_linear <- predict(svm_model_linear, test, type="class")
svm_pred_poly <- predict(svm_model_poly, test, type="class")
svm_pred_radial <- predict(svm_model_radial, test, type="class")
svm_pred_sigmoid <- predict(svm_model_sigmoid, test, type="class")

# Compute accuracy of the SVM model
svm_conf <- table(test$left, svm_pred_linear)
svm_acc <- sum(diag(svm_conf))/sum(svm_conf)
paste("The accuracy of the SVM model with linear kernel is:", svm_acc*100, "%")

svm_conf <- table(test$left, svm_pred_poly)
svm_acc <- sum(diag(svm_conf))/sum(svm_conf)
paste("The accuracy of the SVM model with polynomial kernel is:", svm_acc*100, "%")

svm_conf <- table(test$left, svm_pred_radial)
svm_acc <- sum(diag(svm_conf))/sum(svm_conf)
paste("The accuracy of the SVM model with radial basis kernel is:", svm_acc*100, "%")

svm_conf <- table(test$left, svm_pred_sigmoid)
svm_acc <- sum(diag(svm_conf))/sum(svm_conf)
paste("The accuracy of the SVM model with sigmoid kernel is:", svm_acc*100, "%")

svm_df_radial <- data.frame(test, pred = svm_pred_radial)

# Plot the decision boundary and data points
ggplot(svm_df_radial, aes(x = satisfaction_level, y = last_evaluation, color = pred)) +
  geom_point() +
  geom_contour(aes(z = as.numeric(pred)), alpha = 0.2) +
  scale_color_manual(values = c("#0072B2", "#D55E00"), name = "Predicted") +
  theme_bw()
```

